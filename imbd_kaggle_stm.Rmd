---
title: "imdb_kaggle"
output: html_document
---

```{r setup, include=FALSE}
library(dplyr)
library(quanteda)
library(ggplot2)
library(ggrepel)
library(quanteda.textmodels)
library(stm) 
require(quanteda)
require(quanteda.corpora)
library(igraph)
library(openxlsx)
library(data.table)
library(naniar) 
library(plm) 
theme_set(theme_minimal())
```

## Data preparation

``` {r Import kaggle data}
# Note: Contains some 2020 films, but none of the ones we scraped
kaggle <- read.csv("data/IMDb_movies.csv")

# Exploring the dataset
names(kaggle)

# Selecting variables and remove duplicates 
kaggle1 <- kaggle %>%
  select(title, country, avg_vote, description, duration) %>% 
  rename(rating=avg_vote) %>%
  distinct(title, .keep_all = TRUE) # filter out any duplicates
names(kaggle1)

# convert factors to character columns  
kaggle1 <- kaggle1 %>%
  mutate_if(is.factor, as.character)

# Check column classes
sapply(kaggle1, class)

# Add NA to movies with short descriptions (based on STM req's)
kaggle1[nchar(kaggle1$description) < 35, ] <- NA

# Convert empty and non-English descriptions to NA
kaggle1 <- kaggle1 %>%
  replace_with_na(replace = list(description = "", country = "")) %>%
  replace_with_na(replace = list(title = c("Drei Mann in einem Boot", 
                                           "Tízezer nap",
                                           "Heintje - Einmal wird die Sonne wieder scheinen",
                                           "Az elvarázsolt dollár",
                                           "Szerelem elsö vérig")))

# Remove movies with incomplete (NA) information
kaggle2 <- na.omit(kaggle1)

```


``` {r scraped data}
# Import scraped data 
total <- read.xlsx("data/scraped_data.xlsx")

# Check column classes
sapply(total, class)

# Adjust test dataset to training dataset
dat_test <- total %>% 
  select(Title,Country, Rating, Metascore, Votes, Description, Revenue..Millions.,Runtime..Minutes.) %>% 
  rename(Budget = Revenue..Millions., Duration = Runtime..Minutes.)
names(dat_test)

# Convert numeric to integer 
colsnum <- c("Duration")
dat_test[colsnum] <- sapply(dat_test[colsnum],as.integer)

# Remove movies with incomplete information 
dat2020 <- na.omit(dat_test) 
```

## Structural Topic Model

```{r Initialize Corpus and dfm objects}
######### Kaggle Data ################

# Turn kaggle data into corpus
corp_kaggle <- corpus(kaggle2, 
       text_field = "description",
       docid_field = "title")

# Add titles back
docvars(corp_kaggle, "title") <- kaggle2$title 

# Create a document-feature matrix to enable text analysis
# Note: With no word limits we get 15.003 columns/possible variables
corp_kaggle_dfm <- dfm(corp_kaggle, 
                remove_punct = TRUE, 
                remove_numbers = TRUE,
                remove_symbol = TRUE, 
                remove_separators = TRUE,
                split_hyphens = TRUE,
                remove = stopwords("en")) %>%
  dfm_trim(min_termfreq = 0.9, termfreq_type = "quantile") # keep top 5% of words

######### Scraped Data ################
  
# make corpus from scraped 2020 imdb data
corp_2020 <- corpus(dat2020, 
       text_field = "Description",
       docid_field = "Title")

docvars(corp_2020, "Title") <- dat2020$Title ## Add back Title

# Turn corpus into dfm
corp_2020_dfm <- dfm(corp_2020,
                remove_punct = TRUE,
                remove_symbols = TRUE,
                remove_separators = TRUE,
                split_hyphens = TRUE,
                remove_numbers = TRUE,   
                remove = stopwords("en")) 
```

```{r Structural Topic Model Pt. 1 - build and save}
# Build topic model from kaggle data
# "mod_demo" illustrates the process but "mod" will be used from here on

corp_kaggle_stm <- asSTMCorpus(corp_kaggle_dfm)

# Create STM topic model
mod_demo <- stm(documents = corp_kaggle_stm$documents,
           vocab = corp_kaggle_stm$vocab,
           K = 10,
           data = corp_kaggle_stm$data,
           seed = 12345)

# Save model 
#saveRDS(mod_demo, file = "data/topic_mod_demo.rds")
```

```{r Structural Topic Model Pt. 2 - import and continue}
# Import model
mod <- readRDS("data/topic_mod_v2.rds") 

# Descriptive 
summary(mod) 
# FREX weights words by their overall frequency and how exclusive they are to the topic.
# Lift weights words by dividing by their frequency in other topics, therefore giving higher weight to words that appear less frequently in other topics.
# Similar to lift, score divides the log frequency of the word in the topic by the log frequency of the word in other topics.

# Highest probability words in each topic
plot(mod, type = "summary", text.cex = 1)

# Compare different topic words
plot(mod,
     type = "perspectives",
     topics = c(4, 5),
     main = "Putting two different topics in perspective")
# The size of the words is relative to their frequency (within the combination of the two topics). The x-axis shows the degree that specific words align with Topic 4 or Topic 5. 

topicQuality(mod, documents = corp_kaggle_stm$documents)
# Semantic coherence measures whether the words in a topic tend to co-occur together.
# Exclusivity measures the extent to which the top words for this topic are do not appear as top words in other topics -- i.e., the extent to which its top words are 'exclusive.'
dim(mod$beta$logbeta[[1]])

# Name the topics
labels <- apply(sageLabels(mod)$marginal$frex, 1, 
                function(x){ paste(x[1:4], collapse = "-") })
                # takes FREX words and concatenates them 

# Build df
thetas_kaggle <- data.frame(mod$theta)
colnames(thetas_kaggle) <- labels
rownames(thetas_kaggle) <- paste(docvars(corp_kaggle_dfm)$title)
```

```{r apply topic model to scraped data}
# Turn dfm into STM corpus
new_docs <- asSTMCorpus(corp_2020_dfm)

# Apply old topic model
new_stm <- alignCorpus(new_docs,
                       old.vocab = corp_kaggle_stm$vocab)

# Predict thetas for scraped data based on kaggle model
nds <- fitNewDocuments(mod, documents = new_stm$documents,
                newData = new_stm$data)

thetas_2020 <- data.frame(nds$theta)
colnames(thetas_2020) <- labels
rownames(thetas_2020) <- paste(docvars(corp_2020_dfm)$Title)

```

## Final creation of datasets

```{r combine thetas into full datasets}

# Add topic scores into kaggle df
thetas_kaggle <- setDT(thetas_kaggle, keep.rownames = TRUE)
names(thetas_kaggle)[1] <- "title" 
dat_kaggle <- left_join(kaggle2, thetas_kaggle, by = "title")
dat_kaggle <- select(dat_kaggle, -c(title, description)) # won't use for model

# Add topic scores into scraped data
thetas_2020 <- setDT(thetas_2020, keep.rownames = TRUE)
names(thetas_2020)[1] <- "Title" 
dat_2020 <- left_join(dat2020, thetas_2020, by = "Title")

# Manage multiple countries - keep only first country
dat_kaggle$country <- gsub(",.*$", "\\1", dat_kaggle$country) 
dat_2020$Country <- gsub(",.*$", "\\1", dat_2020$Country)

# Save datasets for analysis 
#saveRDS(dat_kaggle, file = "data/dat_kaggle_demo.rds")
#saveRDS(dat_2020, file = "data/dat_2020_demo.rds")

```

