---
title: "imdb_kaggle"
output: html_document
---

```{r setup, include=FALSE}
library(dplyr)
library(quanteda)
library(ggplot2)
library(ggrepel)
library(quanteda.textmodels)
theme_set(theme_minimal())
library(stm) # NOTE: You might need to install this
require(quanteda)
require(quanteda.corpora)
library(igraph)# NOTE: You might need to install this
library(openxlsx)
```

## Kaggle Data

```{r data preparation}
dat<-read.csv("imdb_1972-2019.csv")

# Exploring the dataset
names(dat)

# Selecting the variables we are going to use and remove duplicates
dat1 <- dat %>% 
  select(Title, Year, Rating, Metascore, Description, Genre, Runtime..Minutes., Revenue..Millions.) %>% 
  distinct(Title, .keep_all = TRUE)
names(dat1)

# Look at duplicates 
dat %>% filter(duplicated(.[["Title"]]))
dat1 %>% filter(duplicated(.[["Title"]])) # to test that filter worked

# convert factors to character columns
dat2 <- dat1 %>%
  mutate_if(is.factor, as.character)

sapply(dat2, class) # to see current classes


###################################
# recreate corpus initialization for scraped data (perhaps move to different script later)

total<-read.xlsx("scraped_data.xlsx")
sapply(total, class) # to see current classes

# Adjust test dataset to training dataset
dat_test <- total %>% 
  select(Title, Year, Rating, Metascore, Description, Genres, Runtime..Minutes., Revenue..Millions.) %>% 
  distinct(Title, .keep_all = TRUE) %>% 
  rename(Genre = Genres)
names(dat_test)

# Convert numeric to integer 
colsnum <- c("Year", "Runtime..Minutes.")
dat_test[colsnum] <- sapply(dat_test[colsnum],as.integer)

# Check conformity 
ifelse(sapply(dat2, class) == sapply(dat_test, class), 1, 0) # if TRUE, return 1; if FALSE, return 0

dat2020 <- na.omit(dat_test) #remove films with missing information in either columns
```

## Structural Topic Model


```{r Initialize Corpus and dfm objects}
# initialize corpus and dfm objects

# Turn kaggle data into corpus
corp1 <- corpus(dat2, 
       text_field = "Description",
       docid_field = "Title")

docvars(corp1, "Title") <- dat1$Title ## Add back Title

# Create a document-feature matrix to enable text analysis
#With no word limits we get 15.003 columns (so possible variables)
corp_dfm <- dfm(corp1, 
                remove_punct = TRUE, 
                remove_numbers = TRUE,
                remove_symbol = TRUE, 
                remove_separators = TRUE,
                split_hyphens = TRUE,
                remove = stopwords("en")) #%>%
  #dfm_trim(min_termfreq = 0.8, termfreq_type = "quantile") 
  # only keeps top 5% of words - play around with (no doc limit)

######### Scraped Data ################
  
# make corpus from scraped 2020 imdb data
corp_2020 <- corpus(dat2020, 
       text_field = "Description",
       docid_field = "Title")

docvars(corp_2020, "Title") <- dat2020$Title ## Add back Title

# make scrapped corpus into dfm 
corp_2020_dfm <- dfm(corp_2020,
                remove_punct = TRUE,
                remove_symbols = TRUE,
                remove_separators = TRUE,
                split_hyphens = TRUE,
                remove_numbers = TRUE,   
                remove = stopwords("en")) 

```

```{r Structural Topic Model}
# build topic model from kaggle data
corp_dfm_stm <- asSTMCorpus(corp_dfm)
mod <- stm(documents = corp_dfm_stm$documents, 
           vocab = corp_dfm_stm$vocab,
           K = 10, 
           data = corp_dfm_stm$data,
           seed = 12345)

# Descriptive 
summary(mod) # shows highest probability, Lift and FREX words and score
# FREX weights words by their overall frequency and how exclusive they are to the topic.
# Lift weights words by dividing by their frequency in other topics, therefore giving higher weight to words that appear less frequently in other topics.
# Similar to lift, score divides the log frequency of the word in the topic by the log frequency of the word in other topics.
plot(mod, type = "summary", text.cex = 1) # shows highest probability words in each topic
plot(mod,
     type = "perspectives",
     topics = c(4, 5),
     main = "Putting two different topics in perspective")
# The size of the words is again relative to their frequency (within the combination of the two topics). The x-axis shows the dregree that specific words align with Topic 4 or Topic 5. 
plot(topicCorr(mod))

topicQuality(mod, documents = corp_dfm_stm$documents)
# Semantic coherence measures whether the words in a topic tend to co-occur together.
# Exclusivity measures the extent to which the top words for this topic are do not appear as top words in other topics -- i.e., the extent to which its top words are 'exclusive.'
dim(mod$beta$logbeta[[1]])

# name the topics
labels <- apply(sageLabels(mod)$marginal$frex, 1, 
                function(x){ paste(x[1:4], collapse = "-") })
                # takes FREX words and concatenates them 

# make dfm into STM corpus
new_docs <- asSTMCorpus(corp_2020_dfm) ## This is where films are dropped if na.omit not run (above)

# apply old topic model
new_stm <- alignCorpus(new_docs,
                       old.vocab = corp_dfm_stm$vocab)

nds <- fitNewDocuments(mod, documents = new_stm$documents,
                newData = new_stm$data)

thetas <- data.frame(nds$theta)
colnames(thetas) <- labels
rownames(thetas) <- paste(docvars(corp_2020_dfm)$Title)

# next step: link this spreadsheet (thetas by topic) to 2020 film data to create model

#probably not useful but cute!
library(ca)
plot(ca(thetas))

```

```{r does not work}

stm1effect <- estimateEffect(formula = 1:10 ~ Rating,
              stmobj = mod,
              metadata = corp_dfm_stm$data)
summary(stm1effect)


# apply topic model
old_stm <- alignCorpus(corp_dfm_stm,
                       old.vocab = corp_dfm_stm$vocab)

nods <- fitNewDocuments(mod, documents = old_stm$documents,
                newData = old_stm$data)

thetas <- data.frame(nods$theta)
colnames(thetas) <- labels
rownames(thetas) <- paste(docvars(corp_dfm)$Title)

# Attach thetas to df - doesn't make sense 
dat3 <- cbind(dat2, thetas)
dat3 <- select(dat3, -c(Title, Description, Genre))

# Model 
mood <- lm(Rating ~ ., data = dat3)
summary(mood)
predict(mood, dat3)

# Test on new data
prediction <- predict(mood, dat2020) # cannot work because categories don't exist
``` 
